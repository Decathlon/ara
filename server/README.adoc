= ARA - Server

SpringBoot/Hibernate/SpringJPA/SpringMVC/QueryDsl back-end.

== Technical Bird View

=== Global Architecture

Here are main layers in the server module, with the main technologies used by the project:

[ditaa]
....
    +---------------+
    |  Liquibase{io}| Create tables in a repeatable fashion
    +-------+-------+
            |
            v
    +---------------+
    |     Table  {s}| Stored in MariaDB (the OpenSource fork of MySQL
    +---------------+ after it has been bought by Oracle)
            |
            | SQL query generated by SpringJPA or QueryDSL
            v
    +---------------+
    |   Repository  | The persistence layer;
    +-------+-------+ the only one doing database queries
            |
            | Repositories return live entities
            v (domain objects, connected to the database for lazy loading)
    +---------------+
    |    Service    | Business logic (can use self-contained Util static methods)
    |           /---+----\
    +-------+---+ Mapper | Transform DTO to/from entities
            |   \--------/
            | Services return DTOs (Data Transfer Objects)
            | with no link to the database transaction; all data are fetched
            v
    +---------------+
    | REST Resource | The presentation layer exposes URLs
    +-------+-------+ to map Java services to Web services
            |
            | DTOs serialized as JSON, with optional HTTP headers
            v
    +---------------+
    |    Swagger{io}| Exposes a live documentation of
    +---------------+ REST APIs at /swagger{dash}ui.html
....

=== Class Diagram

* "NULLABLE" are nullable columns, "" are NOT NULL columns
* *U1, *U2, *U3... are UNIQUE CONSTRAINTS (all columns with the same *Ux suffix are part of the same UNIQUE CONSTRAINT)
* *IA, *IB, *IC... are (not unique) INDEXES (all columns with the same *Ix suffix are part of the same INDEX).
  Indexes automatically created by MySQL for foreign-keys constraints are not represented here as *Ix.
* Primary keys are underlined (use "{static}" prefix in the PlantUML file to do so):
  their automatically-created UNIQUE INDEX is not represented by any *Ux.

[plantuml]
....
include::uml/uml.txt[]
....

=== Execution Crawling Sequence Diagram

[plantuml]
....
include::uml/sequence.txt[]
....

=== Random Hints

We use Spring Boot as the basis of the project: +
https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/

We don't use field injection, but we use constructor injection with Lombok annotations, so we get benefits of both methods: +
http://olivergierke.de/2013/11/why-field-injection-is-evil/

Liquibase Eclipse Plugin can be downloaded here: +
https://code.google.com/archive/p/liquibase-eclipse-plugin/downloads

== Create an ARA Instance/Project for a new Application

=== Hardware recommendations

You need a production machine onto which to install the ARA server (the server also packs the client web-application) and its database (on the same machine):

* RAM: 4 GB (should be OK with 2 GB, but a bit tight)
* CPU: not a real concern: tested on a Xeon 2.2 GHz
* Disk: about 128 GB to be large if you want to stock big files like screenshots, videos, HTTP logs, large Postman requests...

=== Information Required to Configure the Project

* The Git URL(s) of the project (where to find Cucumber .feature files and/or Postman Collection JSON files)
* The defect-tracker (JIRA, RTC...) URL of the project (+ a read-only user to synchronize defect statuses with ARA's problem statuses)
* The continuous-integration (Jenkins...) URL of test executions (+ a read-only user for ARA to crawl and index execution results; if not possible, make the jobs upload a directory so that the FileSystemFetcher is able to discover and read it)
* Data to put into configuration tables: see <<../doc/integrator/main/IntegratorDocumentation.adoc,integrator documentation>>

=== Add Configuration Files

* Create a new folder `ara/server/src/main/resources/config/{app}`, where {app} is the id of your application
* In this folder, create:
** application.properties for global configuration
** application-dev.properties for local development database/schema URL
** prod/application-prod.properties for production-only configuration (without sensitive data like passwords)

Check other application properties files to know what configuration options to (re)define.

=== Plug it in Maven

In ara/server/pom.xml, in the <profiles/> section:

* Duplicate the "dev" <profile/>
* Rename it "dev-{app}", where {app} is the id of your application
* Change the local database schema to the new one, dedicated to running the application on your development machine

=== Create the Production Launch Script

* Duplicate `ara/server/scripts/ara-service-{an-app}.sh` and rename {an-app} it with your application id ({app} used
  elsewhere in this documentation)
* Edit it, change the app variable with your application id, and the sensitive passwords (we advise you to retrieve them
  from secret files on the target production machine)

=== Make Jenkins Deploy the Application

In ara/Jenkinsfile, duplicate one "Deployment: " stage and make it point to your server and application id.

=== Insert Configuration Data

Once you installed a machine, create the schema:

    CREATE DATABASE `ara-prod`;

See next chapter for more details (the next chapter is for a local development machine, but can be adapted for a
production machine).

Run the setup once, so Liquibase has a chance to create all tables.

== Setup Development Machine

=== Install MariaDB
Download MariaDB here, version 5.5.56 (same version than on server): +
https://downloads.mariadb.org/mariadb/5.5.56/

Follow this tutorial: +
https://mariadb.com/kb/fr/installing-mariadb-msi-packages-on-windows/ +
For the root password, use V*n6MxBq7mr?4P?M +
Check “Use UTF-8 as default server’s character set” +
Keep other default choice (server port 3306, optimize for transactions, etc.)

Go to “C:\Program Files\MariaDB 5.5\data” +
Open my.ini as an Administrator, and paste this content:

    [mysqld]
    datadir=C:/Program Files/MariaDB 5.5/data
    port=3306
    sql_mode="STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION"
    default_storage_engine=innodb
    innodb_buffer_pool_size=2033M
    innodb_log_file_size=50M
    character-set-server=utf8
    innodb_large_prefix
    innodb_file_format=BARRACUDA
    innodb_file_per_table
    innodb_file_format_max=BARRACUDA
    autocommit=OFF
    [client]
    port=3306

Press Win+R, execute “services.msc” and restart the “MySQL” service for it to use the new configuration.

=== Create Data Bases
You can download MySQL Workbench GPL (the equivalent to SQL Developer):
https://dev.mysql.com/downloads/workbench/

Connect via MySql Workbench, and execute:

    CREATE DATABASE `ara-dev-in`;

This will be the schema used by integration tests on your local development environment.

Then, for each application you will maintain, create a schema for running the application on your local development machine:

    CREATE DATABASE `ara-{app}-dev`;

Where `{app}` is the id of your application(s).

If you work on ARA Core, you CAN create this schema to test a core ARA (without application-dependant configuration):

    CREATE DATABASE `ara-dev`;

=== Initialize the Development Data Base
To create the tables, run this command in ara-server directory:

    mvn -Dspring.config.location=classpath:/,classpath:/config/{app}/ liquibase:updateTestingRollback -P{profile}

Where `{app}` is the id of your application and `{profile}` is the profile linked to your app in the `ara-server/pom.xml` file. +
Repeat for each application you maintain.

Then, to populate some data, you can initiate the Demo project :

* Run Ara server and Ara client
* Go the Dropdown menu in the top left corner
* Click on Manage Project List
* At the center of the screen, click on the button "Create the Demo project"

If you work on ARA Core, you CAN initiate this schema to test a core ARA (without application-dependant configuration):

    mvn liquibase:updateTestingRollback -Pdev

=== Install Lombok in Your IDE

It's provided with IntelliJ IDEA. +
But it must be installed on Eclipse.

=== Set Up IDE Automatic Formatter

* link:../ide-resources/intellij/README.adoc[Configure IntelliJ IDEA]
* link:../ide-resources/eclipse/README.adoc[Configure Eclipse]

== Compile & Run the Project

=== JDK Version

You need a JDK 8. There are some breaking changes in Java 9 and Java 10 that prevent ARA from compiling. +
While waiting for https://github.com/querydsl/querydsl/issues/2242 to be solved, we will keep using Java 8.

=== Spring Profiles

By default, all Spring properties are read in application.properties. +
But for database and other external server configurations, we use profiles to configure such different environments:

* dev: development environment, to develop/run/test/debug on local machine with a local database
* dev_in: run integration tests on a local machine with a local database, but on a separate empty database schema
* in: used by continuous integration to run integration tests
* prod: once deployed on the final production server

To launch compilations and tests, you need to set the dev_in profile:

    mvn install -Dspring.profiles.active=dev_in

To update the development database schema and be able to run ARA on your local machine, run tis command, with the dev profile:

    mvn liquibase:update -Dspring.profiles.active=dev

This will not skip integration tests: when you run integration tests, you need to be run on *dev_in* environment, and NOT on *in* environment: only the continuous integration server will use it. So you can develop your integration tests, run and debug them on your own modified environment (new database table, etc.).

=== First Execution

==== Set up Spring profile in your IDE

When executing Maven commands in your IDE, make sure to set the Maven profile to dev_in. +
In IntelliJ, in the view "Maven Projects", unfold the first folder "Profiles" and check "dev_in". +
Then, in this "Maven Projects" view, you will be able to execute any lifecycle without having to set the profile.

==== Make sure IntelliJ Generates MapStruct Classes the Correct Way

In IntelliJ, use "Reimport All Maven Projects" in order for compilation flags to be added correctly.

Or better: enable the "Import Maven projects automatically" option in IntelliJ -> File -> Settings -> Build, Execution, Deployment -> Build Tools -> Maven -> Importing.

Alternatively, make sure this option is here:

IntelliJ -> File -> Settings -> Build, Execution, Deployment -> Compiler -> Java Compiler +
Override compiler parameters per-module: +
Module "ara-server" Compilation options "-Amapstruct.defaultComponentModel=spring -Amapstruct.unmappedTargetPolicy=IGNORE"

With these options, the IntelliJ compiler will generate MapStruct class implementations with the Spring @Component annotation.

==== First Compilation

First do a "mvn install -Pdev_in" in the root of the ARA project. +
This will generate the client and ara-generated-cucumber-report dependencies for the server module to compile. +
This will also generate the Q* and S* classes (the QueryDsl classes) to make your IDE happy.

==== Run the Server

First, in a terminal, go to the client module and run "npm run dev" to have a live-reload version of the client on http://localhost:8080

Then, on the server part, create a Spring Boot run configuration:

* Main class: com.decathlon.ara.AraApplication
* Active Profiles: dev (if you don't have the Intellij Ultimate version, use the VM arg : `-Dspring.profiles.active=dev` )
* VM options: `-Dspring.config.location=classpath:/,classpath:/config/{app}/` where you replace `{app}` by the application you want to launch (see below)
* VM options: `-DdocUrl=<location of your docs if you host them on a different server or http://localhost>`
* Spring Boot Settings: Override parameters:
** key: ara.sshPassword / value: ((you know it, it is a secret))

Here are some details about the application-specific configuration folder of the above `classpath:/config/{app}/`. +
For a new application, create a `server/src/main/resources/config/{app}` folder, and add:

* `application.properties`: configure the following properties:
** `spring.mail.host`: SMTP host (mandatory to sent email reports, eg. 'smtp.gmail.com')
** `spring.mail.port`: SMTP port (mandatory to sent email reports, eg. '587')
** `spring.mail.username`: SMTP username (optional, could be your email address)
** `spring.mail.password`: SMTP password (optional)
** `spring.mail.properties.mail.smtp.auth`: SMTP auth (optional, 'true' or 'false')
** `spring.mail.properties.mail.smtp.starttls.enable`: SMTP starts TLS (optional, 'true' or 'false')
* `application-dev.properties`: used on development machines:
** `spring.datasource.url`: the database URL
* `prod/application-prod.properties`:
** `spring.datasource.url`: the database URL
** `spring.datasource.username`: the database login
** `spring.datasource.password`: the database password
** `ara.clientBaseUrl`: the URL on which your ARA is deployed, as seen by your users
   (used to generate links in sent report emails)
** `ara.executionSchedulingEnabled=true` to enable execution indexing (1/3)
** `ara.executionSchedulingDelayInMilliseconds=60000` to enable execution indexing (2/3)
** `ara.executionSchedulingInitialDelayInMilliseconds=10000` to enable execution indexing (3/3)

You can run it to get a working server part, talking to the client you launched above.

You will have no execution history. +
In order to index latest non-regression-tests you need to:

* Duplicate the run configuration, and name it "AraApplication with indexing", for instance
* Add these program arguments:
** --ara.executionSchedulingEnabled=true
** --ara.executionSchedulingDelayInMilliseconds=60000
** --ara.executionSchedulingInitialDelayInMilliseconds=0

Stop the currently running server. +
Launch this new server run configuration and wait until latest executions get indexed automatically. +
This can take some time. +
This is why we advise you to run this command only when needing to test the indexing code: you will use the first run configuration without indexing when developing and testing other codes.

=== Useful Commands

* ??? to run the application (without compiling it as a JAR), only the server side (with hot-reload): you must run the client side too with eg. ``npm run dev``
* When running a JUnit integration test (*IT.java): VM args = ``-Dspring.profiles.active=dev_in``
* ``mvn liquibase:updateTestingRollback -Pdev`` to update the development database schema
* ``mvn install -Pdev_in`` to compile, package and install the application, running all tests
* ``mvn install -Pdev_in -DskipITs=true`` to compile, package and install the application, keeping unit tests, but bypassing slow integration tests
* ``mvn install -Pdev_in -DskipTests=true -DskipITs=true`` to compile, package and install the application, bypassing all tests, or to regenerate the mapping classes or the entity and table classes if database schema changed
* ``mvn install -Pdev_in -Dmaven.test.skip=true`` to compile, package and install the application, without even compiling test classes
* ``java -Dspring.profiles.active=dev -jar target/ara-server-*.jar`` to run the produced application, including the client in the server
* ``mvn install -Pdev_in -DskipPitest`` to skip Pitest tests (mutates the code and check at least one test is failing, to make sure no equivalent to assert(true) is done in tests)

== Liquibase

When designing Liquibase change-sets, you may find out the new change-set is erroneous and want to undo it and replace it with a fixed version.

You can rollback the last applied change-set with this command:

    mvn -Dliquibase.rollbackCount=1 liquibase:rollback -Pdev_in

Change the rollbackCount to tell Liquibase the number of change-sets to rollback. +
Change the profile to point to the right database.

IMPORTANT: Only do this on your local development environment, while designing a NEW change-set, and before committing the final version to the master branch of the project. +
Once a change-set has gone to production, you must not modify it.

All change-sets of ARA need to be rollbackable: when applying the change-sets, a rollback test is performed in order to check for problems (and then the change-set is applied again, of course). +
Keep a look at the http://www.liquibase.org/documentation/changes/create_table.html[Liquibase documentation]: some tags have "Auto Rollback" support, like the &lt;createTable/> (which automatically drops the table on rollback), but some other tags do not have automatic rollback: you need to provide a &lt;rollback/> tag alongside the change-set. +
Sometimes, there is nothing to rollback, so you can add an empty <&lt;rollback/> tag. +
Be careful: an empty &lt;rollback/> tag removes all auto-rollback mechanisms of the change-set and replace them with the one you provide: if you provide an empty <&lt;rollback/> tag, then no rollback procedure will be done.

== How to add or modify a table

Wherever possible, copy another class and adapt it, to get all useful Lombok annotations and best practices:

* Create a new liquibase XML file to add the table: +
  src/main/resources/liquibase/changelog/00000100_create_table_team.xml +
  One changeLog XML file can be split in several changeSets as needed
  (eg. one to add a column, another to migrate data, and a last one to remove the old column...)
* Declare the new changeLog in src/main/resources/liquibase/master.xml
* Add a new entity in src/main/java com.decathlon.ara.domain
* Be careful to include a business-key in @EqualsAndHashCode and keep this business key in sync with compareTo():
  see https://developer.jboss.org/wiki/EqualsAndHashCode (so we can put the entities in sets) +
  The primary key can be hidden to users (eg. if it's a uniquely-generated Long ID),
  but the business key is always visible: it is a unique set of columns that is presented to the user as the uniquely
  identifying columns of the table (the business key CAN be the primary key, if it's a String code the user filled at
  entity creation). The business key is also used by Hibernate to identify entities in a set (via compareTo/equals).
  The business key also needs a unique constraint to enforce it.
* Don't forget to create unique constraints, foreign keys and indices where needed.
* Add a new data transfer object in src/main/java com.decathlon.ara.service.dto
* Add a new entity<=>DTO mapper in src/main/java com.decathlon.ara.service.mapper
* Add a new repository in src/main/java com.decathlon.ara.repository
* Add a new service in src/main/java com.decathlon.ara.service
* Add a new REST resource in src/main/java com.decathlon.ara.service.web.rest
* Add all needed *Test classes for unit-tests and/or *IT classes for integration tests
* Update the file uml.txt to document the new table
* Add the table in com.decathlon.ara.dbunit.DbUnitExporter for easy data migration and/or integration-test creation
* Add a Level-2 Hibernate cache in src/main/resources/ehcache.xml (caches are declared in alphabetical order)
* If it is a new configuration table, in the client project, add a new management-*.vue,
  using the crud.vue component to generate the table and create/edit window with little efforts

Note: if a column in the table is multi-words, use underscore_case naming for the column and camelCase for the entity field: Spring & Hibernate will translate camelCase to underscore_case automatically: no need to add @Column annotation in this simple case

Some tips:

* If a DTO is an input DTO (to edit some entity from an HTTP request),
  add validation annotations (on DTOs, not on entities)
  (if a DTO is only an output DTO, it will never be validated: do not put validation annotations on it):

** For optional fields (no @NotNull nor minimum @Size):

    @Size(max = 128, message = "The name must not exceed {max} characters.")

** For required fields (@NotNull AND minimum @Size):

    @NotNull(message = "The name is required.")
    @Size(min = 1, max = 128, message = "The name is required and must not exceed {max} characters.")

* For required fields, entity classes must have primitive types (char, boolean, int...)
  BUT, for DTO classes, object types must be used instead (String (and not Character), Boolean, Integer...):
  this is counter-intuitive, but is needed to make @NotNull and @Size (for char/String) validations work,
  and return a user-friendly error on missing field in the JSON, instead of a raw JSON parsing error.

[FeatFlip]
== How to add a Feature Flipping

If you're dealing with an unstable feature and want to activate it only on certain instances of ARA (like a
Canary deployment or a AB Testing), you can surround your feature code by a Feature flipping. ARA has an
API to deal with enabling or not features based on an in-memory flag.

First we need to create a class which will holds our flipping informations. This class must implements
`IFeature`. Once you do it, register your new flipping class in the constructor of `FeatureCollection` class.

You can then add a default state for the feature (enabled or not), in the spring `application.properties` :
`ara.features.<code>=<state>` where `<code>` is the value returned by
your feature `getCode()` method and `<state>` set to `true` if enabled or `false` if disabled.

Note that the resolution of a feature default state (state at the application init) is calculated following
those rules :

* the value is setted in system property `-Dara.features.<code>=<state>`
* if not, the value is setted in the spring application.properties file `ara.features.<code>=<state>`
* if not, the value is `false`.

Once your ARA instance is live, you can update the current state of a feature flipping using the
`<host>:<port>/api/features/` API (see the swagger documentation for more informations).

== Swagger

Swagger is a documentation and test tool for APIs. +
All REST resources must have JavaDoc so that it can be used for public API documentation. +
You can access to it at http://localhost:8080/swagger-ui.html

== Tests & Quality

=== Unit Tests vs. Integration Tests

Remember Maven's build lifecycle phases:

* validate - validate the project is correct and all necessary information is available
* compile - compile the source code of the project
* test - test the compiled source code using a suitable unit testing framework. These tests should not require the code be packaged or deployed
* package - take the compiled code and package it in its distributable format, such as a JAR.
* verify - run any checks on results of integration tests to ensure quality criteria are met
* install - install the package into the local repository, for use as a dependency in other projects locally
* deploy - done in the build environment, copies the final package to the remote repository for sharing with other developers and projects.

For this project:

* JUnit tests are *very fast to execute and self-contained* (everything is mocked, except the component to test) => they run on 'mvn test' thanks to the Maven Surefire plugin. They are in *src/test/java* and their file name ends with *Test.java*. They can be skipped with the mvn -DskipTests parameter
* Integration tests require the start of the *Spring context*, and possibly also a *database access* or *download/upload files* => they run on 'mvn verify' thanks to the Maven Failsafe plugin. They are in *src/test/java* and their file name ends with *IT.java*. They can be skipped with the mvn -DskipITs parameter (they are also skipped when -DskipTests is positioned)

So you could:

* prefer 'mvn package' for fast repeated compilations (with unit-tests execution)
* and 'mvn install' from time to time to test everything is well integrated (but this can take minutes to run)
* or 'mvn compile' to generate new MapStruct mappers without running any test.

TIP: When running integration tests, you can use the VM arguments `-XX:TieredStopAtLevel=1 -noverify` to speed up Spring context startup

=== PiTest (for Unit Tests)

We are using PiTest: it adds mutations in your code and run unit-tests (not integration-tests) to check at least one unit-test fails with the modified code. +
This ensures code is robust and completely tested (no "assert true" ;-) but in reality, such "assert true" can be quite well hidden inside real tests). +

Pitest is quite time consuming to run. +
When working on adding or modifying tests to a class, you can run Pitest only on the given class, using the following command. +
Note that Pitest needs the tests to have run for it to compute code coverage and know what classes to mutate.

    mvn test -DskipPitest -Pdev_in && \
    mvn pitest:mutationCoverage \
        -DtargetClasses=com.decathlon.ara.postman.service.PostmanService \
        -DtargetTests=com.decathlon.ara.postman.service.PostmanServiceTest \
        -Pdev_in

It's only an example: you can specify only one class to test (PostmanService) and one test class (PostmanServiceTest). +
The test-class is optional: by default, all test-classes will be candidates to test mutations.

=== Run all Tests in your IDE

Create this run configuration in your IDE to run all tests (Unit Tests AND Integration Tests):

* Type: JUnit
* Pattern of classes to run: `\^.*Test$||^.*TestSuite$||\^.*IT$||^.*ITSuite$` +
  (if viewing the asciiDoc source, remove the anti-slashes when copy/pasting)
* VM options: `-ea -Dspring.jpa.properties.hibernate.hbm2ddl.auto=none`

=== Run only Unit Tests in your IDE

As this can potentially be long, you can run only unit tests by creating this run configuration in your IDE:

* Type: JUnit
* Pattern of classes to run: `\^.*Test$||^.*TestSuite$` +
  (if viewing the asciiDoc source, remove the anti-slashes when copy/pasting)
* VM options: `-ea -Dspring.jpa.properties.hibernate.hbm2ddl.auto=none`

== Export/Import Databases and Create Integration-Test Data-Sets or Test Liquibase Scripts Against Real Data

=== Why?

There are database export and import helper classes too. +
This can be handy to:

* Export real production environment to import it on a local empty environment
* Or to update a pre-production environment
* Export a real database and manually-cure a subset of it to generate integration test data

=== Export a Database

To export a database, create this run configuration in your IDE:

* Type: JUnit
* Class: `com.decathlon.ara.dbunit.DbUnitExporter`
* VM options (change the profile to export another schema, and replace {app} with your application id):

    -ea
    -Dspring.profiles.active=dev
    -Dspring.config.location=classpath:/,classpath:/config/{app}

=== Export the Production Database

To export the production database, create this run configuration in your IDE:

* Type: JUnit
* Class: `com.decathlon.ara.dbunit.DbUnitExporter`
* VM options (replace {app} TWICE with your application id):

    -ea
    -Dspring.profiles.active=prod
    -Dspring.config.location=classpath:/,classpath:/config/{app},classpath:/config/{app}/prod/
    -Dara.executionSchedulingEnabled=false

* BE CAREFUL: do not execute any other class with these parameters, as this could corrupt production database (this class is safe, as it's only reading from production)

=== Import a Database Locally

To import the database locally (here, on your dev schema/profile), create this run configuration in your IDE:

* Type: JUnit
* Class: `com.decathlon.ara.dbunit.DbUnitImporter`
* VM options (replace {app} TWICE with your application id):

    -ea
    -Dspring.profiles.active=dev
    -Dspring.config.location=classpath:/,classpath:/config/{app}
    -Dspring.datasource.url=jdbc:mysql://localhost:3306/ara-{app}-dev?useUnicode=yes&characterEncoding=UTF-8&sessionVariables=FOREIGN_KEY_CHECKS=0
